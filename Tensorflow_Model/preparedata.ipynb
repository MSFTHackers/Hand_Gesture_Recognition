{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import sys\n",
    "import pandas as pd\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "  def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "def image_sequence(directory):\n",
    "    \"\"\"this function takes a list of images and returns the list in bytes\"\"\"\n",
    "    image_bytes_list = []\n",
    "    for image in sorted((get_unify_frames(directory))):\n",
    "        img = open(directory+\"/\"+image, 'rb').read()\n",
    "        if img is None:\n",
    "            continue\n",
    "        image_bytes = tf.train.Feature(bytes_list=tf.train.BytesList(value=[img]))\n",
    "        image_bytes_list.append(image_bytes)\n",
    "\n",
    "    return image_bytes_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataRecord(out_dirname, addrs, labels, imsize, dataset):\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    \n",
    "    image_height = imsize[0]\n",
    "    image_width = imsize[1]\n",
    "    image_depth = imsize[2]\n",
    "    \n",
    "    writer = tf.io.TFRecordWriter(dataset+'.tfrecords')\n",
    "\n",
    "    \n",
    "    for i in range(len(addrs)):\n",
    "        # open the TFRecords file\n",
    "        # print how many images are saved every 1000 images\n",
    "        if not i % 1000:\n",
    "          print(str(i) +\",\"+ str(len(addrs)))\n",
    "          sys.stdout.flush()\n",
    "        \n",
    "        image_bytes_list = image_sequence(addrs[i])            # Load the image\n",
    "        label_int_list  = [_float_feature(labels[i])]*len(image_bytes_list)\n",
    "        images = tf.train.FeatureList(feature=image_bytes_list)\n",
    "        labels_dat = tf.train.FeatureList(feature=label_int_list)\n",
    "\n",
    "        im_length = tf.train.Feature(int64_list=tf.train.Int64List(value=[len(image_bytes_list)]))\n",
    "        im_height = tf.train.Feature(int64_list=tf.train.Int64List(value=[image_height]))\n",
    "        im_width = tf.train.Feature(int64_list=tf.train.Int64List(value=[image_width]))\n",
    "        im_depth = tf.train.Feature(int64_list=tf.train.Int64List(value=[image_depth]))\n",
    "        \n",
    "        # Create a feature\n",
    "        feature = {\n",
    "        'Images': images,\n",
    "        'Labels': labels_dat\n",
    "        }\n",
    "        \n",
    "        context_dict = {'length': im_length, 'height': im_height, 'width': im_width, 'depth': im_depth}\n",
    "\n",
    "        sequence_context = tf.train.Features(feature=context_dict)\n",
    "\n",
    "        \n",
    "        \n",
    "        # Create an example protocol buffer\n",
    "        example = tf.train.SequenceExample(context=sequence_context, feature_lists=tf.train.FeatureLists(feature_list=feature))\n",
    "        # Serialize to string and write on the file\n",
    "        writer.write(example.SerializeToString())\n",
    "          \n",
    "    writer.close()\n",
    "    sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The videos do not have the same number of frames, here we try to unify.\n",
    "'''\n",
    "hm_frames = 30 # number of frames\n",
    "# unify number of frames for each training\n",
    "def get_unify_frames(path):\n",
    "    offset = 0\n",
    "    # pick frames\n",
    "    frames = os.listdir(path)\n",
    "    frames_count = len(frames)\n",
    "    # unify number of frames \n",
    "    if hm_frames > frames_count:\n",
    "        # duplicate last frame if video is shorter than necessary\n",
    "        frames += [frames[-1]] * (hm_frames - frames_count)\n",
    "    elif hm_frames < frames_count:\n",
    "        # If there are more frames, then sample starting offset\n",
    "        #diff = (frames_count - hm_frames)\n",
    "        #offset = diff-1 \n",
    "        frames = frames[0:hm_frames]\n",
    "    return frames\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLabels():\n",
    "  labels = []\n",
    "  imagesPath = '/kaggle/input/gesturevid/20bn50_part1'\n",
    "  dirs = os.listdir(imagesPath)\n",
    "  # Finally, classes label you want to use all labels \n",
    "  label = pd.read_csv('/kaggle/input/gesture-vid-label1/jester-v1-labels.csv',header=None, usecols=[0])\n",
    "  label.head()\n",
    "  targets_name = label[0].tolist()\n",
    "  # training targets stored\n",
    "  targets_temp = pd.read_csv('/kaggle/input/gesturevid-label/jester-v1-train.csv',header=None,sep = \";\").to_dict()\n",
    "  targets = {}\n",
    "  for index in range(len(targets_temp[0])):\n",
    "    targets[targets_temp[0][index]] = targets_temp[1][index]\n",
    "\n",
    "  for dir in dirs:\n",
    "    labels.append(targets_name.index(targets[int(dir)]))\n",
    "    #todo: del targets{} if not required later\n",
    "  return labels\n",
    "# read addresses and labels from the 'train' folder\n",
    "images_train_path = '/kaggle/input/gesturevid/20bn50_part1/*'\n",
    "addrs = glob.glob(images_train_path)\n",
    "labels = createLabels()\n",
    "# Divide the data into 60% train, 20% validation, and 20% test\n",
    "# Better to use sklearn train-test split. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,35568\n",
      "1000,35568\n",
      "2000,35568\n",
      "3000,35568\n",
      "4000,35568\n",
      "5000,35568\n",
      "6000,35568\n",
      "7000,35568\n",
      "8000,35568\n",
      "9000,35568\n",
      "10000,35568\n",
      "11000,35568\n",
      "12000,35568\n",
      "13000,35568\n",
      "14000,35568\n",
      "15000,35568\n",
      "16000,35568\n",
      "17000,35568\n",
      "18000,35568\n",
      "19000,35568\n",
      "20000,35568\n",
      "21000,35568\n",
      "22000,35568\n",
      "23000,35568\n",
      "24000,35568\n",
      "25000,35568\n",
      "26000,35568\n",
      "27000,35568\n",
      "28000,35568\n",
      "29000,35568\n",
      "30000,35568\n",
      "31000,35568\n",
      "32000,35568\n",
      "33000,35568\n",
      "34000,35568\n",
      "35000,35568\n",
      "0,11856\n",
      "1000,11856\n",
      "2000,11856\n",
      "3000,11856\n",
      "4000,11856\n",
      "5000,11856\n",
      "6000,11856\n",
      "7000,11856\n",
      "8000,11856\n",
      "9000,11856\n",
      "10000,11856\n",
      "11000,11856\n",
      "0,11857\n",
      "1000,11857\n",
      "2000,11857\n",
      "3000,11857\n",
      "4000,11857\n",
      "5000,11857\n",
      "6000,11857\n",
      "7000,11857\n",
      "8000,11857\n",
      "9000,11857\n",
      "10000,11857\n",
      "11000,11857\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_addrs = addrs[0:int(0.6*len(addrs))]\n",
    "train_labels = labels[0:int(0.6*len(labels))]\n",
    "val_addrs = addrs[int(0.6*len(addrs)):int(0.8*len(addrs))]\n",
    "val_labels = labels[int(0.6*len(addrs)):int(0.8*len(addrs))]\n",
    "test_addrs = addrs[int(0.8*len(addrs)):]\n",
    "test_labels = labels[int(0.8*len(labels)):]\n",
    "\n",
    "!mkdir /kaggle/working/train_rec/\n",
    "!mkdir /kaggle/working/val_rec/\n",
    "!mkdir /kaggle/working/test_rec/\n",
    "\n",
    "createDataRecord('/kaggle/working/train_rec/', train_addrs, train_labels, (64,64,1), 'train')\n",
    "createDataRecord('/kaggle/working/val_rec/', val_addrs, val_labels, (64,64,1), 'val')\n",
    "createDataRecord('/kaggle/working/test_rec/', test_addrs, test_labels, (64,64,1), 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
