{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly\r\n",
      "  Downloading tf_nightly-2.4.0.dev20200727-cp37-cp37m-manylinux2010_x86_64.whl (324.8 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 324.8 MB 3.0 kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (0.9.0)\r\n",
      "Collecting flatbuffers>=1.12\r\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (0.2.0)\r\n",
      "Collecting tb-nightly<3.0.0a0,>=2.4.0a0\r\n",
      "  Downloading tb_nightly-2.4.0a20200727-py3-none-any.whl (6.7 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 6.7 MB 37.1 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.11.2)\r\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (0.3.3)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.14.0)\r\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (0.34.2)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (3.2.1)\r\n",
      "Requirement already satisfied: astunparse==1.6.3 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.6.3)\r\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (3.12.2)\r\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.30.0)\r\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.18.5)\r\n",
      "Collecting tf-estimator-nightly\r\n",
      "  Downloading tf_estimator_nightly-2.4.0.dev2020072701-py2.py3-none-any.whl (459 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 459 kB 40.6 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.1.0)\r\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (2.10.0)\r\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tf-nightly) (1.1.2)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.4.1)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.0.1)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.7.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.2.1)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.14.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2.23.0)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.2.0)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.1.1)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (4.0)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2020.6.20)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (1.24.3)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (2.9)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (3.0.1)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<3.0.0a0,>=2.4.0a0->tf-nightly) (0.4.8)\r\n",
      "Installing collected packages: flatbuffers, tb-nightly, tf-estimator-nightly, tf-nightly\r\n",
      "Successfully installed flatbuffers-1.12 tb-nightly-2.4.0a20200727 tf-estimator-nightly-2.4.0.dev2020072701 tf-nightly-2.4.0.dev20200727\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/part1dataset/train.tfrecords\n",
      "/kaggle/input/validationtfrecords/val.tfrecords\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import sys\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " class DataSequenceReader():\n",
    "    def __init__(self, batch_size, num_epochs):\n",
    "        self.batch_size = batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "    \n",
    "    def parse_sequence(self, sequence_example):\n",
    "\n",
    "        sequence_features = {'Images': tf.io.FixedLenSequenceFeature([], dtype=tf.string),\n",
    "                          'Labels': tf.io.FixedLenSequenceFeature([], dtype=tf.int64)}\n",
    "\n",
    "        context_features = {'length': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "                         'height': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "                         'width': tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "                         'depth': tf.io.FixedLenFeature([], dtype=tf.int64)}\n",
    "        \n",
    "        context, sequence = tf.io.parse_single_sequence_example(\n",
    "            sequence_example, context_features=context_features, sequence_features=sequence_features)\n",
    "        # get features context\n",
    "        seq_length = tf.cast(context['length'], dtype = tf.int32)\n",
    "        im_height = tf.cast(context['height'], dtype = tf.int32)\n",
    "        im_width = tf.cast(context['width'], dtype = tf.int32)\n",
    "        im_depth = tf.cast(context['depth'], dtype = tf.int32)\n",
    "\n",
    "        # encode image\n",
    "        image = tf.map_fn(lambda x: tf.io.decode_jpeg(x, 1), sequence['Images'], tf.uint8)\n",
    "        image = tf.cast(image, dtype = tf.float32)\n",
    "        image = tf.reshape(image, shape=(seq_length, im_height, im_width, im_depth))\n",
    "        image = tf.image.per_image_standardization(image)\n",
    "        label = tf.cast(sequence['Labels'], dtype = tf.int32)\n",
    "\n",
    "        return image, label[0]\n",
    "    \n",
    "    def read_batch(self, filename):\n",
    "        \n",
    "\n",
    "        dataset = tf.data.TFRecordDataset(filename)\n",
    "        dataset = dataset.map(self.parse_sequence)\n",
    "\n",
    "        dataset = dataset.shuffle(buffer_size=10000)\n",
    "\n",
    "        dataset = dataset.batch(self.batch_size, drop_remainder=True)\n",
    "        \n",
    "#         dataset = dataset.repeat(self.num_epochs)\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My model\n",
    "# Convolutions\n",
    "conv1 = tf.compat.v2.keras.layers.Conv3D(32, (3, 3, 3), activation='elu', name=\"conv1\", data_format='channels_last')\n",
    "pool1 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2), data_format='channels_last')\n",
    "conv2 = tf.compat.v2.keras.layers.Conv3D(64, (3, 3, 3), activation='elu', name=\"conv2\", data_format='channels_last')\n",
    "pool2 = tf.keras.layers.MaxPool3D(pool_size=(2, 2,2), data_format='channels_last')\n",
    "\n",
    "conv3 = tf.compat.v2.keras.layers.Conv3D(64, (3, 3, 3), activation='elu', name=\"conv3\", data_format='channels_last')\n",
    "pool3 = tf.keras.layers.MaxPool3D(pool_size=(2, 2,2), data_format='channels_last')\n",
    "\n",
    "# LSTM & Flatten\n",
    "convLSTM =tf.keras.layers.ConvLSTM2D(40, (3, 3))\n",
    "flatten =  tf.keras.layers.Flatten(name=\"flatten\")\n",
    "\n",
    "# Dense layers\n",
    "d1 = tf.keras.layers.Dense(128, activation='relu', name=\"d1\")\n",
    "out = tf.keras.layers.Dense(27, activation='softmax', name=\"output\")\n",
    "\n",
    "#BatchNorm\n",
    "b1 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "b2 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "b3 = tf.keras.layers.BatchNormalization(axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "#Dropout\n",
    "drop1 = tf.keras.layers.Dropout(.5)\n",
    "drop2 = tf.keras.layers.Dropout(.5)\n",
    "drop3 = tf.keras.layers.Dropout(.5)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv1)\n",
    "model.add(b1)\n",
    "model.add(drop1)\n",
    "model.add(pool1)\n",
    "model.add(conv2)\n",
    "model.add(b2)\n",
    "model.add(drop2)\n",
    "model.add(pool2)\n",
    "model.add(conv3)\n",
    "model.add(b3)\n",
    "model.add(drop3)\n",
    "model.add(pool3)\n",
    "model.add(convLSTM)\n",
    "model.add(flatten)\n",
    "model.add(d1)\n",
    "model.add(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device('/device:GPU:0'):\n",
    "# #with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
    "#   model = Conv3DModel()\n",
    "# Loss\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
    "# Accuracy\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Make a prediction on all the batch\n",
    "        predictions = model(image)\n",
    "        # Get the error/loss on these predictions\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    # Compute the gradient which respect to the loss\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    # Change the weights of the model\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    # The metrics are accumulate over time. You don't need to average it yourself.\n",
    "    train_loss(loss)\n",
    "    train_accuracy(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def valid_step(image, targets):\n",
    "    predictions = model(image)\n",
    "    t_loss = loss_fn(targets, predictions)\n",
    "    # Set the metrics for the test\n",
    "    valid_loss(t_loss)\n",
    "    valid_accuracy(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Train step done--\n",
      "1\n",
      "tf.Tensor(1.8736979, shape=(), dtype=float32) tf.Tensor(41.5463, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3105254, shape=(), dtype=float32) tf.Tensor(57.01291, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "2\n",
      "tf.Tensor(1.1811628, shape=(), dtype=float32) tf.Tensor(60.883503, shape=(), dtype=float32)\n",
      "tf.Tensor(1.056187, shape=(), dtype=float32) tf.Tensor(65.83774, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "3\n",
      "tf.Tensor(0.9769924, shape=(), dtype=float32) tf.Tensor(67.562096, shape=(), dtype=float32)\n",
      "tf.Tensor(0.97520566, shape=(), dtype=float32) tf.Tensor(67.928406, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "4\n",
      "tf.Tensor(0.8397965, shape=(), dtype=float32) tf.Tensor(71.98805, shape=(), dtype=float32)\n",
      "tf.Tensor(0.93669873, shape=(), dtype=float32) tf.Tensor(69.703636, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "5\n",
      "tf.Tensor(0.73388296, shape=(), dtype=float32) tf.Tensor(75.31892, shape=(), dtype=float32)\n",
      "tf.Tensor(0.9155842, shape=(), dtype=float32) tf.Tensor(71.12676, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "6\n",
      "tf.Tensor(0.6460742, shape=(), dtype=float32) tf.Tensor(78.11994, shape=(), dtype=float32)\n",
      "tf.Tensor(0.8883856, shape=(), dtype=float32) tf.Tensor(71.76496, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "7\n",
      "tf.Tensor(0.5627411, shape=(), dtype=float32) tf.Tensor(80.67967, shape=(), dtype=float32)\n",
      "tf.Tensor(0.90493417, shape=(), dtype=float32) tf.Tensor(72.33715, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "8\n",
      "tf.Tensor(0.50318015, shape=(), dtype=float32) tf.Tensor(82.73151, shape=(), dtype=float32)\n",
      "tf.Tensor(0.89086676, shape=(), dtype=float32) tf.Tensor(73.88498, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "9\n",
      "tf.Tensor(0.43479136, shape=(), dtype=float32) tf.Tensor(84.99932, shape=(), dtype=float32)\n",
      "tf.Tensor(0.91766924, shape=(), dtype=float32) tf.Tensor(73.268776, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "10\n",
      "tf.Tensor(0.38220036, shape=(), dtype=float32) tf.Tensor(86.62426, shape=(), dtype=float32)\n",
      "tf.Tensor(0.98888826, shape=(), dtype=float32) tf.Tensor(73.041374, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "11\n",
      "tf.Tensor(0.33231837, shape=(), dtype=float32) tf.Tensor(88.18676, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0005077, shape=(), dtype=float32) tf.Tensor(73.356804, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "12\n",
      "tf.Tensor(0.29046986, shape=(), dtype=float32) tf.Tensor(89.700325, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0591011, shape=(), dtype=float32) tf.Tensor(73.386154, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "13\n",
      "tf.Tensor(0.25982773, shape=(), dtype=float32) tf.Tensor(90.79711, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1154532, shape=(), dtype=float32) tf.Tensor(73.06338, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "14\n",
      "tf.Tensor(0.23171695, shape=(), dtype=float32) tf.Tensor(91.82134, shape=(), dtype=float32)\n",
      "tf.Tensor(1.1750998, shape=(), dtype=float32) tf.Tensor(72.34448, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "15\n",
      "tf.Tensor(0.20186977, shape=(), dtype=float32) tf.Tensor(92.78483, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2260331, shape=(), dtype=float32) tf.Tensor(72.88733, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "16\n",
      "tf.Tensor(0.18391407, shape=(), dtype=float32) tf.Tensor(93.47833, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2484899, shape=(), dtype=float32) tf.Tensor(73.2321, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "17\n",
      "tf.Tensor(0.16734537, shape=(), dtype=float32) tf.Tensor(94.01998, shape=(), dtype=float32)\n",
      "tf.Tensor(1.2682999, shape=(), dtype=float32) tf.Tensor(73.00469, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "18\n",
      "tf.Tensor(0.15693446, shape=(), dtype=float32) tf.Tensor(94.38445, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3771229, shape=(), dtype=float32) tf.Tensor(73.034035, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "19\n",
      "tf.Tensor(0.15533417, shape=(), dtype=float32) tf.Tensor(94.458694, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3572412, shape=(), dtype=float32) tf.Tensor(73.20276, shape=(), dtype=float32)\n",
      "--Train step done--\n",
      "20\n",
      "tf.Tensor(0.13734718, shape=(), dtype=float32) tf.Tensor(95.035774, shape=(), dtype=float32)\n",
      "tf.Tensor(1.3835577, shape=(), dtype=float32) tf.Tensor(73.613556, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size =32\n",
    "num_epochs = 20\n",
    "data = DataSequenceReader(batch_size, num_epochs)\n",
    "\n",
    "train_batch = data.read_batch('/kaggle/input/part1dataset/train.tfrecords')\n",
    "val_batch = data.read_batch('/kaggle/input/validationtfrecords/val.tfrecords')\n",
    "\n",
    "count=0\n",
    "\n",
    "training_acc =[]\n",
    "validation_acc = []\n",
    "\n",
    "\n",
    "with tf.device('/device:GPU:0'):\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        for images, labels in train_batch:\n",
    "            train_step(images, labels)\n",
    "\n",
    "\n",
    "        for images, labels in val_batch:\n",
    "            valid_step(images, labels)\n",
    "\n",
    "        print(\"--Train step done--\")\n",
    "        count=count+1\n",
    "        print(count)\n",
    "\n",
    "        print(train_loss.result(), train_accuracy.result()*100)\n",
    "        print(valid_loss.result(), valid_accuracy.result()*100)\n",
    "\n",
    "        training_acc.append(float(train_accuracy.result()*100))\n",
    "        validation_acc.append(float(valid_accuracy.result()*100))\n",
    "\n",
    "\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "\n",
    "        valid_loss.reset_states()\n",
    "        valid_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/kaggle/working/my_model', save_format='h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (32, 28, 62, 62, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (32, 28, 62, 62, 32)      128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (32, 28, 62, 62, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D) (32, 14, 31, 31, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (32, 12, 29, 29, 64)      55360     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (32, 12, 29, 29, 64)      256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (32, 12, 29, 29, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (32, 6, 14, 14, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv3D)               (32, 4, 12, 12, 64)       110656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (32, 4, 12, 12, 64)       256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (32, 4, 12, 12, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (32, 2, 6, 6, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d (ConvLSTM2D)    (32, 4, 4, 40)            149920    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (32, 640)                 0         \n",
      "_________________________________________________________________\n",
      "d1 (Dense)                   (32, 128)                 82048     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (32, 27)                  3483      \n",
      "=================================================================\n",
      "Total params: 403,003\n",
      "Trainable params: 402,683\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
